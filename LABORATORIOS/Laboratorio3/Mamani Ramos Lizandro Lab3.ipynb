{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3\n",
    "\n",
    "- Nombre: Mamani Ramos Lizandro\n",
    "\n",
    "## Ejemplificación de uso de clasificación multiclase (one vs all) para un modelo de regresión logística \n",
    "\n",
    "> Dataset orientado a calcular la cantidad de coronas que obtuvo el ganador de una partida de Clash Royale (1,2,3) en base a la cantidad de tropas, niveles de cartas, cantidad de hechizos,etc. Tanto del oponente como del rival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Importamos numpy para el manejo de arreglos y operaciones matemáticas\n",
    "import numpy as np  \n",
    "\n",
    "# Importamos pandas para el manejo de datos en forma de dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Importamos la libreria para el manejo de datos en forma de tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "# para la separación de datos en entrenamiento y prueba 80\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modulo de optimizacion en scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Carga de datos del dataset con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80000 entries, 0 to 79999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   winner.crowns           80000 non-null  float64\n",
      " 1   loser.crowns            80000 non-null  float64\n",
      " 2   winner.totalcard.level  80000 non-null  int64  \n",
      " 3   winner.troop.count      80000 non-null  int64  \n",
      " 4   winner.structure.count  80000 non-null  int64  \n",
      " 5   winner.spell.count      80000 non-null  int64  \n",
      " 6   winner.common.count     80000 non-null  int64  \n",
      " 7   winner.rare.count       80000 non-null  int64  \n",
      " 8   winner.epic.count       80000 non-null  int64  \n",
      " 9   winner.legendary.count  80000 non-null  int64  \n",
      " 10  winner.elixir.average   80000 non-null  float64\n",
      " 11  loser.totalcard.level   80000 non-null  int64  \n",
      " 12  loser.troop.count       80000 non-null  int64  \n",
      " 13  loser.structure.count   80000 non-null  int64  \n",
      " 14  loser.spell.count       80000 non-null  int64  \n",
      " 15  loser.common.count      80000 non-null  int64  \n",
      " 16  loser.rare.count        80000 non-null  int64  \n",
      " 17  loser.epic.count        80000 non-null  int64  \n",
      " 18  loser.legendary.count   80000 non-null  int64  \n",
      " 19  loser.elixir.average    80000 non-null  float64\n",
      "dtypes: float64(4), int64(16)\n",
      "memory usage: 12.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Lectura del dataset con las columnas necesarias y tomando un total de 80000 registros\n",
    "data = pd.read_csv('/home/dilpz/Documentos/SIS420-2024/datasets/BattlesStaging_01012021_WL_tagged.csv', usecols=[39,40,41,42,43,44,45,46,47,65,66,67,68,69,70,71,72,73,16,8], nrows=80000)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas a usar para la hipotesis \"Y\" y \"X\" para el entrenamiento\n",
    "### Y= (winner.crowns)\n",
    "\n",
    "### X = winner.totalcard.level, winner.troop.count, winner.structure.count, winner.spell.count, winner.common.count, winner.rare.count, winner.epic.count, winner.legendary.count winner.elixir.average , loser.crowns , loser.totalcard.level, loser.troop.count, loser.structure.count, loser.spell.count, loser.common.count, loser.rare.count, loser.epic.count, loser.legendary.count , loser.elixir.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de clases presentes son: \n",
      "1.0    39695\n",
      "3.0    21407\n",
      "2.0    18898\n",
      "Name: winner.crowns, dtype: int64\n",
      "\n",
      "Cantidad de NaN por columna después de llenar los datos faltantes:\n",
      "winner.crowns             0\n",
      "loser.crowns              0\n",
      "winner.totalcard.level    0\n",
      "winner.troop.count        0\n",
      "winner.structure.count    0\n",
      "winner.spell.count        0\n",
      "winner.common.count       0\n",
      "winner.rare.count         0\n",
      "winner.epic.count         0\n",
      "winner.legendary.count    0\n",
      "winner.elixir.average     0\n",
      "loser.totalcard.level     0\n",
      "loser.troop.count         0\n",
      "loser.structure.count     0\n",
      "loser.spell.count         0\n",
      "loser.common.count        0\n",
      "loser.rare.count          0\n",
      "loser.epic.count          0\n",
      "loser.legendary.count     0\n",
      "loser.elixir.average      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Conteo de los valores para identificar las clases resultantes\n",
    "class_counts = data[\"winner.crowns\"].value_counts()\n",
    "\n",
    "# Imprimir los valores de las clases resultantes\n",
    "print(f'La cantidad de clases presentes son: ')\n",
    "print(class_counts)\n",
    "\n",
    "# Revision de los valores nan para verificar si existen y llenar con la media si es posible\n",
    "print(\"\\nCantidad de NaN por columna después de llenar los datos faltantes:\")\n",
    "print(data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas con valores faltantes\n",
    "\n",
    "# Para la clase 0\n",
    "data_class_0 = data[data['winner.crowns'] == 1]\n",
    "train_class_0, test_class_0 = train_test_split(data_class_0, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 1\n",
    "data_class_1 = data[data['winner.crowns'] == 2]\n",
    "train_class_1, test_class_1 = train_test_split(data_class_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 2\n",
    "data_class_2 = data[data['winner.crowns'] == 3]\n",
    "train_class_2, test_class_2 = train_test_split(data_class_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner.crowns</th>\n",
       "      <th>loser.crowns</th>\n",
       "      <th>winner.totalcard.level</th>\n",
       "      <th>winner.troop.count</th>\n",
       "      <th>winner.structure.count</th>\n",
       "      <th>winner.spell.count</th>\n",
       "      <th>winner.common.count</th>\n",
       "      <th>winner.rare.count</th>\n",
       "      <th>winner.epic.count</th>\n",
       "      <th>winner.legendary.count</th>\n",
       "      <th>winner.elixir.average</th>\n",
       "      <th>loser.totalcard.level</th>\n",
       "      <th>loser.troop.count</th>\n",
       "      <th>loser.structure.count</th>\n",
       "      <th>loser.spell.count</th>\n",
       "      <th>loser.common.count</th>\n",
       "      <th>loser.rare.count</th>\n",
       "      <th>loser.epic.count</th>\n",
       "      <th>loser.legendary.count</th>\n",
       "      <th>loser.elixir.average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52621</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46903</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36898</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32804</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55190</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33495</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69770</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>103</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31580</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46279</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.553571</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       winner.crowns  loser.crowns  winner.totalcard.level  \\\n",
       "52621            2.0           1.0                     104   \n",
       "46903            2.0           0.0                     104   \n",
       "36898            2.0           1.0                     103   \n",
       "32804            2.0           1.0                      69   \n",
       "55190            2.0           1.0                     103   \n",
       "...              ...           ...                     ...   \n",
       "17594            2.0           1.0                     104   \n",
       "33495            2.0           0.0                     104   \n",
       "69770            2.0           1.0                     102   \n",
       "31580            2.0           1.0                      85   \n",
       "46279            2.0           1.0                      93   \n",
       "\n",
       "       winner.troop.count  winner.structure.count  winner.spell.count  \\\n",
       "52621                   7                       0                   1   \n",
       "46903                   6                       1                   1   \n",
       "36898                   6                       0                   2   \n",
       "32804                   6                       0                   2   \n",
       "55190                   5                       1                   2   \n",
       "...                   ...                     ...                 ...   \n",
       "17594                   7                       0                   1   \n",
       "33495                   5                       1                   2   \n",
       "69770                   6                       0                   2   \n",
       "31580                   6                       0                   2   \n",
       "46279                   5                       0                   3   \n",
       "\n",
       "       winner.common.count  winner.rare.count  winner.epic.count  \\\n",
       "52621                    1                  3                  3   \n",
       "46903                    3                  2                  1   \n",
       "36898                    2                  2                  4   \n",
       "32804                    3                  1                  1   \n",
       "55190                    1                  6                  1   \n",
       "...                    ...                ...                ...   \n",
       "17594                    2                  1                  1   \n",
       "33495                    4                  1                  0   \n",
       "69770                    2                  5                  1   \n",
       "31580                    3                  1                  0   \n",
       "46279                    2                  2                  2   \n",
       "\n",
       "       winner.legendary.count  winner.elixir.average  loser.totalcard.level  \\\n",
       "52621                       1               4.375000                     98   \n",
       "46903                       2               3.500000                    104   \n",
       "36898                       0               4.000000                     98   \n",
       "32804                       3               4.250000                     77   \n",
       "55190                       0               4.250000                    101   \n",
       "...                       ...                    ...                    ...   \n",
       "17594                       4               3.500000                    104   \n",
       "33495                       3               3.750000                    104   \n",
       "69770                       0               3.375000                    103   \n",
       "31580                       4               3.000000                     84   \n",
       "46279                       2               4.553571                    104   \n",
       "\n",
       "       loser.troop.count  loser.structure.count  loser.spell.count  \\\n",
       "52621                  7                      0                  1   \n",
       "46903                  6                      0                  2   \n",
       "36898                  7                      0                  1   \n",
       "32804                  5                      1                  2   \n",
       "55190                  6                      0                  2   \n",
       "...                  ...                    ...                ...   \n",
       "17594                  6                      0                  2   \n",
       "33495                  4                      1                  3   \n",
       "69770                  6                      0                  2   \n",
       "31580                  8                      0                  0   \n",
       "46279                  4                      3                  1   \n",
       "\n",
       "       loser.common.count  loser.rare.count  loser.epic.count  \\\n",
       "52621                   4                 2                 0   \n",
       "46903                   2                 3                 3   \n",
       "36898                   0                 3                 3   \n",
       "32804                   1                 4                 3   \n",
       "55190                   3                 1                 3   \n",
       "...                   ...               ...               ...   \n",
       "17594                   0                 4                 3   \n",
       "33495                   3                 1                 2   \n",
       "69770                   1                 5                 1   \n",
       "31580                   1                 2                 4   \n",
       "46279                   4                 4                 0   \n",
       "\n",
       "       loser.legendary.count  loser.elixir.average  \n",
       "52621                      2              3.500000  \n",
       "46903                      0              4.375000  \n",
       "36898                      2              4.982143  \n",
       "32804                      0              3.875000  \n",
       "55190                      1              4.000000  \n",
       "...                      ...                   ...  \n",
       "17594                      1              4.250000  \n",
       "33495                      2              4.553571  \n",
       "69770                      1              3.500000  \n",
       "31580                      1              4.375000  \n",
       "46279                      0              4.125000  \n",
       "\n",
       "[3780 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impresion de los datos de test \n",
    "test_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Class 0  Class 1  Class 2  Total\n",
      "Total          39695    18898    21407  80000\n",
      "Train (80%)    31756    15118    17125      -\n",
      "Test (20%)      7939     3780     4282      -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a dictionary to hold the data\n",
    "data_dict = {\n",
    "    \"Class 0\": [data_class_0.shape[0], train_class_0.shape[0], test_class_0.shape[0]],\n",
    "    \"Class 1\": [data_class_1.shape[0], train_class_1.shape[0], test_class_1.shape[0]],\n",
    "    \"Class 2\": [data_class_2.shape[0], train_class_2.shape[0], test_class_2.shape[0]],\n",
    "    \"Total\": [data.shape[0], \"-\", \"-\"]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data_dict, index=[\"Total\", \"Train (80%)\", \"Test (20%)\"])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar las caracteristicas de la etiqueta para la parte de entrenamiento y pruebas\n",
    "#para la clase 0\n",
    "X_train_class_0 = train_class_0.drop(['winner.crowns'], axis=1)\n",
    "y_train_class_0 = train_class_0['winner.crowns']\n",
    "\n",
    "#para la clase 1\n",
    "X_train_class_1 = train_class_1.drop(['winner.crowns'], axis=1)\n",
    "y_train_class_1 = train_class_1['winner.crowns']\n",
    "\n",
    "#para la clase 2\n",
    "X_train_class_2 = train_class_2.drop(['winner.crowns'], axis=1)\n",
    "y_train_class_2 = train_class_2['winner.crowns']\n",
    "\n",
    "#ahora para la parte de pruebas, separamos las caracteristicas de la etiqueta\n",
    "#para la clase 0\n",
    "X_test_class_0 = test_class_0.drop(['winner.crowns'], axis=1)\n",
    "y_test_class_0 = test_class_0['winner.crowns']\n",
    "\n",
    "#para la clase 1\n",
    "X_test_class_1 = test_class_1.drop(['winner.crowns'], axis=1)\n",
    "y_test_class_1 = test_class_1['winner.crowns']\n",
    "\n",
    "#para la clase 2\n",
    "X_test_class_2 = test_class_2.drop(['winner.crowns'], axis=1)\n",
    "y_test_class_2 = test_class_2['winner.crowns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de los datos en entrenamiento y prueba\n",
    "X_train = pd.concat([X_train_class_0, X_train_class_1, X_train_class_2]).values\n",
    "y_train = pd.concat([ y_train_class_0, y_train_class_1, y_train_class_2]).values\n",
    "\n",
    "indices_train = np.random.permutation(len(X_train))\n",
    "X_train = X_train[indices_train]\n",
    "y_train = y_train[indices_train]\n",
    "m_train = len(y_train)\n",
    "\n",
    "####################################################\n",
    "\n",
    "X_test = pd.concat([X_test_class_0, X_test_class_1, X_test_class_2]).values\n",
    "y_test = pd.concat([y_test_class_0, y_test_class_1, y_test_class_2]).values\n",
    "\n",
    "indices_test = np.random.permutation(len(X_test))\n",
    "X_test = X_test[indices_test]\n",
    "y_test = y_test[indices_test]\n",
    "m_test = len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de X_train son: (63999, 19)\n",
      "Las dimensiones de y_train son: (63999,)\n",
      "Las dimensiones de X_test son: (16001, 19)\n",
      "Las dimensiones de y_test son: (16001,)\n"
     ]
    }
   ],
   "source": [
    "#imprimir los datos de entrenamiento\n",
    "print(f\"Las dimensiones de X_train son: {X_train.shape}\")\n",
    "print(f\"Las dimensiones de y_train son: {y_train.shape}\")\n",
    "\n",
    "#imprimir los datos de prueba\n",
    "print(f\"Las dimensiones de X_test son: {X_test.shape}\")\n",
    "print(f\"Las dimensiones de y_test son: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creación de la función de normalización de los datos\n",
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #inicializamos las variables necesarias para la normalización\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #calculamos la media y la desviación estándar de cada columna en X\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos restando la media y dividiendo por la desviación estándar\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62929274, -1.22980887, -2.38949691, ...,  1.23276601,\n",
       "        -0.48294474,  1.73307556],\n",
       "       [-0.62929274,  0.66578202, -0.55225708, ...,  0.52779798,\n",
       "        -1.28809166,  0.5406115 ],\n",
       "       [ 1.34686556, -1.22980887,  0.36636283, ...,  2.64270206,\n",
       "         0.32220219,  0.77910431],\n",
       "       ...,\n",
       "       [-0.62929274,  0.30124531,  0.36636283, ..., -0.88213807,\n",
       "         1.12734911,  0.06362587],\n",
       "       [ 1.34686556,  0.66578202,  0.36636283, ...,  0.52779798,\n",
       "        -1.28809166, -0.65185257],\n",
       "       [-0.62929274, -2.10469697, -0.55225708, ...,  1.23276601,\n",
       "         0.32220219,  2.72111722]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizacion de características\n",
    "X_norm, mu, sigma = featureNormalize(X_train)\n",
    "#Impresion de los datos normalizados y verificar si estan correctos\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definición de la función sigmoide para el cálculo\n",
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "    #Agregamos la columna de unos a la matriz X\n",
    "    g = np.zeros(z.shape)\n",
    "    #Calculo de lasigmoide para cada valor de z en la matriz\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad que son las variables que vamos a retornar correspondientes al costo y el gradiente\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "    # m es el número de ejemplos de entrenamiento\n",
    "    # n es el número de características\n",
    "    # num_labels es el número de etiquetas\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas\n",
    "    all_theta = np.zeros((num_labels, 20))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador que recibe\n",
    "    # lrCostFunction como función de costo\n",
    "    # initial_theta es un vector de ceros\n",
    "    # jac=True indica que la función de costo devuelve el gradiente\n",
    "    # method='CG' es un método de optimización\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 1000}\n",
    "        res = optimize.minimize(lrCostFunction,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c), lambda_),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20)\n",
      "[[-1.24380805e+01  1.34549043e-12 -4.64507102e-12  4.85777505e-12\n",
      "  -3.70220831e-12 -3.64259816e-12 -3.03293901e-12 -1.76994381e-12\n",
      "   2.47280504e-12  2.22295090e-12  3.03403266e-12 -4.63435287e-12\n",
      "   3.15237689e-12 -1.68276294e-12 -2.71173395e-12 -1.45707535e-12\n",
      "  -8.47815548e-13  1.08358531e-12  1.19194548e-12  1.62620659e-12]\n",
      " [-2.77062821e+00 -5.88275606e+00 -4.56799385e-01 -1.54777459e-01\n",
      "   2.03438179e-01  5.83539836e-02 -5.53512304e-02  9.41291245e-03\n",
      "  -5.12865427e-03  5.61582819e-02 -1.86147830e-01  9.29189773e-01\n",
      "  -9.29914129e-03  6.77851946e-02 -3.58242277e-02 -6.13585719e-02\n",
      "  -4.23949074e-02  5.43163388e-02  4.72485513e-02 -6.03627812e-02]\n",
      " [-1.57378210e+00  1.40243669e+00  7.08519523e-02  1.91816326e-02\n",
      "  -4.10951029e-02  3.50729214e-03  1.98039770e-02  3.39838521e-02\n",
      "  -4.74794645e-02 -1.07258219e-03 -6.89331781e-02  6.60332619e-02\n",
      "   1.17018656e-02 -1.95160639e-02 -8.05469502e-04 -2.03297960e-02\n",
      "   2.30925993e-02 -1.44745794e-02  1.41804398e-02  6.46118911e-02]\n",
      " [-1.12740075e+00  2.96288165e-01  3.49969001e-01  1.23686006e-01\n",
      "  -1.80624131e-01 -3.44260023e-02  2.30851146e-02 -2.37064523e-02\n",
      "   3.35343050e-02 -3.97328668e-02  2.09146057e-01 -7.88852867e-01\n",
      "   1.86080543e-03 -4.15553665e-02  2.66933161e-02  6.30587079e-02\n",
      "   1.99168457e-02 -4.00725716e-02 -4.19870647e-02  9.61623355e-03]]\n"
     ]
    }
   ],
   "source": [
    "# que valor de lambda uso?\n",
    "lambda_ = 0.05\n",
    "all_theta = oneVsAll(X_norm, y_train, 4, lambda_)\n",
    "print(all_theta.shape)\n",
    "print(all_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # añadimos unos a la matriz de X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 71.07%\n"
     ]
    }
   ],
   "source": [
    "pred_test = predictOneVsAll(all_theta, X_norm)\n",
    "print('Precision del conjunto de entrenamiento: {:.2f}%'.format(np.mean(pred_test == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de prueba: 49.67%\n"
     ]
    }
   ],
   "source": [
    "X_test1 = X_test.copy()\n",
    "X_test = (X_test1 - mu) / sigma\n",
    "pred_train = predictOneVsAll(all_theta, X_test1)\n",
    "print('Precision del conjunto de prueba: {:.2f}%'.format(np.mean(pred_train == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la función de normalización de características para normalizar los datos de prueba y agregar la columna de unos\n",
    "X_test1 = (X_test1 - mu) / sigma\n",
    "X_test1 = np.concatenate([np.ones((len(X_test1), 1)), X_test1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 50 predicciones realizadas:\n",
      "[1 2 1 1 1 2 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 2 1 1 1 1 1 2 2 1 2 1 2 1 2 1 3\n",
      " 1 2 1 1 1 1 2 1 1 1 1 1 1]\n",
      "Cantidad de predicciones correctas: 11409\n",
      "Numero de '1' en la prediccion: 10377\n",
      "Numero de '2' en la prediccion: 4242\n",
      "Numero de '3' en la prediccion: 1382\n",
      "Cantidad de veces que el modelo predijo correctamente la columna y o winner.crowns: 11409\n"
     ]
    }
   ],
   "source": [
    "# Assuming that 'all_theta' and 'y' are defined and 'y' is the actual labels\n",
    "# Assuming that 'sigmoid' function is defined\n",
    "\n",
    "# Calculate the predictions\n",
    "p = np.argmax(sigmoid(X_test1.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "# Print the first 50 predictions\n",
    "print(\"Primeras 50 predicciones realizadas:\")\n",
    "print(p[:50])\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = np.sum(p == y_test)\n",
    "print(f\"Cantidad de predicciones correctas: {correct_predictions}\")\n",
    "\n",
    "# Count the number of 1, 2, 3 in the predictions\n",
    "count_1 = np.sum(p == 1)\n",
    "count_2 = np.sum(p == 2)\n",
    "count_3 = np.sum(p == 3)\n",
    "print(f\"Numero de '1' en la prediccion: {count_1}\")\n",
    "print(f\"Numero de '2' en la prediccion: {count_2}\")\n",
    "print(f\"Numero de '3' en la prediccion: {count_3}\")\n",
    "\n",
    "# Count the number of matches between the prediction and y\n",
    "matches = np.sum(p == y_test)\n",
    "print(f\"Cantidad de veces que el modelo predijo correctamente la columna y o winner.crowns: {matches}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
